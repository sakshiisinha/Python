{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPI9efimsWK8MP8+LkVJL1J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakshiisinha/Python/blob/main/text_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYRjMRzepQGu",
        "outputId": "d7bb1602-2bee-4c0c-ae4d-70ff8d3dda0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "# mounting the drive to read the data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "X4nJEhjkqTfH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reading the data from local google drive\n",
        "with open('/content/drive/my drive/colab Notebooks/data/robert_frost.txt')as story\n",
        "story_data = story.read()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "KOypcFm_qdms",
        "outputId": "b469c2ef-860e-43d8-9829-7d97d8530364"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "expected ':' (<ipython-input-5-35e3ed23f1cd>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-35e3ed23f1cd>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    with open('/content/drive/my drive/colab Notebooks/data/robert_frost.txt')as story\u001b[0m\n\u001b[0m                                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (story_data)"
      ],
      "metadata": {
        "id": "VURKfOp8rCe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A buttoning coats to ask him who he was.\n",
        "He proved to be the city come again\n",
        "To look for something it had left behind\n",
        "And could not do without and keep its christmas.\n",
        "He asked if I would sell my christmas trees;\n",
        "My wood the young balsams like a place\n",
        "where houses all are churches and have spires,\n",
        "I hadn't thought off their feet to go in cars\n",
        "And leave the slope behind the houses all bare,\n",
        "Where the sun shines now no warmer than moon,\n",
        "I'd hate to have then know it if I wa.\n",
        "Yet more I'd hate to hold my tree except\n",
        "As others hold theirs or refuse for then,\n",
        "Beyond the time of profitablevgrowth,\n",
        "The trial by market everything must come to.\n"
      ],
      "metadata": {
        "id": "T4p0DoT5uEQq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "erdP1hEf9RBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data cleansing process\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "  return text"
      ],
      "metadata": {
        "id": "Bkkx2Bp_rJeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = final.split('\\n')\n",
        "print(final_data)"
      ],
      "metadata": {
        "id": "LT3fQit0wPuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "kKHmRpXkxDFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiating the tokenizer\n",
        "max_vocab = 1000\n",
        "tokenizer = Tokenizer(num_words_max_vocab)\n",
        "tokenizer.fit_on_texts(final_data)"
      ],
      "metadata": {
        "id": "M4-gp1UzxdGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the total number of words of the data.\n",
        "word21dx = tokenizer.word_index\n",
        "print(len(word21dx))\n",
        "print(word21dx)\n",
        "vocab_size = len(word21dx) + 1\n",
        "print(vocab_size)\n"
      ],
      "metadata": {
        "id": "ivznRdwLyPUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#turn the sentences line by line and create n_gram sequence\n",
        "\n",
        "input_seq = []\n",
        "\n",
        "for line in final_data;\n",
        "token_list = tokenizer.texts_to_sequence((line))[0]\n",
        "for i in range(1, len(token_list)):\n",
        "  n_green_seq = token_list[:i+1]\n",
        "  input_seq.append(n_gram_seq)"
      ],
      "metadata": {
        "id": "nJy_8h1izCO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_seq)"
      ],
      "metadata": {
        "id": "0xoGTppizCh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the maximum lenght of sequence for padding purpose\n",
        "max_seq_length = max(len(x)for x in input_seq)\n",
        "print(max_input_seq)"
      ],
      "metadata": {
        "id": "y8997czazClA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding the sequences and converting them to array\n",
        "input_seq = np.array(pad_sequences(input_seq, maxlen=max_seq_lenght, padding'pre'))\n",
        "print(input_seq)"
      ],
      "metadata": {
        "id": "6w_m7Cn_0z8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking xs labels to train the model.\n",
        "\n",
        "xs = input_seq[:i + 1]\n",
        "print(\"xs: \",xs)\n",
        "print(\"labels:\",labels)"
      ],
      "metadata": {
        "id": "OEwu90mA00Mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras,utils import to categorical"
      ],
      "metadata": {
        "id": "UEDwyvo000PN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encoding the labels according to the vocab size\n",
        "\n",
        "# The matrix is square matrix of the size of vocab_size, each row will denote a label and it will have\n",
        "# a single +ve value(i.e 1)for that label and other values will be zero.\n",
        "\n",
        "ys = to_categorical(labels, num_classes = vocab_size)\n",
        "print(ys)"
      ],
      "metadata": {
        "id": "nirAXPFO00SX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Dense, embedding, LSTH, Dropout\n",
        "from tensorflow.keras.model import model\n",
        "from tensorflow.keras.optimizer import adam\n",
        "from tensorflow.keras.model import sequential"
      ],
      "metadata": {
        "id": "Ww5J3XRi00U5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using the functional APIS of keras to define the model\n",
        "\n",
        "i = input(shape=(max_seq_length - 1))\n",
        "x = embedding(vocab_size,124(i))\n",
        "x = Dropout(0.2)(x)\n",
        "x = LSTH(520, return_sequences = True)(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "\n",
        "model = model(i,x)"
      ],
      "metadata": {
        "id": "6z0xxQa200YO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = adam(1r - 0.001)\n",
        "              loss = categorical_crossentrophy',\n",
        "              matrics = ['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "JtHbE1wbzCod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = model.summary()"
      ],
      "metadata": {
        "id": "Uu1Wse1JzCxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model on accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(r.history['accuracy'])"
      ],
      "metadata": {
        "id": "AvlVcB1h68Uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the model\n",
        "\n",
        "model.save('pose generator.sh') #will create a HDFS file of the model"
      ],
      "metadata": {
        "id": "eEOCeLnp7TQM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}